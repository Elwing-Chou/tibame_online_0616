{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZlw9eC0uP7TQog8uY40tK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/tibame_online_0616/blob/main/tibame_night_20250708.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "HTTP代碼\n",
        "1. 2: 成功\n",
        "2. 3: 轉址\n",
        "3. 4: 錯誤\n",
        "403 Forbidden\n",
        "1. IP被ban: 換ip/等\n",
        "2. 模仿不夠像: 缺少必要headers\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ou5S_xGAwqE3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vKOQkRPVuQvr"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import urllib.request as req\n",
        "import bs4 as bs\n",
        "\n",
        "url = \"https://www.ptt.cc/bbs/Beauty/M.1751797464.A.265.html\"\n",
        "r = req.Request(url)\n",
        "r.add_header(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0\")\n",
        "resp = req.urlopen(r)\n",
        "content = resp.read()\n",
        "html = bs.BeautifulSoup(content)\n",
        "# find/find_all\n",
        "# .text .get_text() [\"href\"]\n",
        "\n",
        "# 作者/標題/時間/看板\n",
        "metas = html.find_all(\"span\", {\"class\":\"article-meta-value\"})\n",
        "author = metas[0]\n",
        "board = metas[1]\n",
        "title = metas[2]\n",
        "post_time = metas[3]\n",
        "pushes = html.find_all(\"div\", {\"class\":\"push\"})\n",
        "\n",
        "\n",
        "author_text = author.text\n",
        "board_text = board.text\n",
        "title_text = title.text\n",
        "post_time_text = post_time.text\n",
        "\n",
        "push_list = []\n",
        "for p in pushes:\n",
        "    push_meta = p.find_all(\"span\")\n",
        "    push_trans = {\"推\":1, \"噓\":-1, \"→\":0}\n",
        "    push_data = {\n",
        "        \"type\":push_trans[push_meta[0].text.strip()],\n",
        "        \"uid\":push_meta[1].text.strip(),\n",
        "        \"text\":push_meta[2].text.strip().replace(\": \", \"\"),\n",
        "        \"ipdatetime\":push_meta[3].text.strip()\n",
        "    }\n",
        "    push_list.append(push_data)\n",
        "\n",
        "# 內文: 沒有任何區塊把內文包起來, 先找到大區塊, 把區塊裡面你不要的東西去掉(extract)\n",
        "main_content = html.find(\"div\", {\"id\":\"main-content\"})\n",
        "for e in html.find_all(\"div\", {\"class\":\"article-metaline\"}):\n",
        "    e.extract()\n",
        "for e in html.find_all(\"div\", {\"class\":\"article-metaline-right\"}):\n",
        "    e.extract()\n",
        "for e in html.find_all(\"div\", {\"class\":\"push\"}):\n",
        "    e.extract()\n",
        "# print(main_content)\n",
        "content_text = main_content.text.strip()\n",
        "\n",
        "\n",
        "row = {\n",
        "    \"author\":author_text,\n",
        "    \"title\":title_text,\n",
        "    \"post_time\":post_time_text,\n",
        "    \"board\":board_text,\n",
        "    \"pushes\":push_list,\n",
        "    \"content\":content_text,\n",
        "}\n",
        "# print(row)\n",
        "fn = url.split(\"/\")[-1] + \".json\"\n",
        "with open(fn, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(row, f, indent=4, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"a.txt\", \"w\", encoding=\"utf-8\")\n",
        "f.write(\"abc\")\n",
        "f.close()\n",
        "\n",
        "with open(\"a.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"abc\")"
      ],
      "metadata": {
        "id": "KqmIYcU82jKR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as req\n",
        "\n",
        "# 相對路徑:\n",
        "# a.txt: 現在這個目錄下的a.txt\n",
        "# ./a.txt: 現在(.)這個目錄下的a.txt\n",
        "# ../a.txt: 前一層目錄(..)的a.txt\n",
        "def get_imgur_image(url, dirname=\".\"):\n",
        "    # dirname = \"file\"\n",
        "    # url = \"https://i.imgur.com/OSwXeuz.jpeg\"\n",
        "    r = req.Request(url)\n",
        "    r.add_header(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0\")\n",
        "    resp = req.urlopen(r)\n",
        "    content = resp.read()\n",
        "\n",
        "    # 檔案讀寫\n",
        "    # 1. 純文字: r/w  encoding=\"utf-8\"\n",
        "    # 2. 非純文字(jpeg, png, docx, xlsx, pdf...): rb/wb\n",
        "    fp = dirname + \"/\" + url.split(\"/\")[-1]\n",
        "    with open(fp, \"wb\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "url = \"https://i.imgur.com/H8i2ZVT.jpeg\"\n",
        "get_imgur_image(url)"
      ],
      "metadata": {
        "id": "6cehbYhVNLHG"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}